# âš¡ LibrerÃ­a de MetaheurÃ­sticas con AceleraciÃ³n por Hardware y Soporte para ClÃºster

ğŸŒ Disponible en: [ğŸ‡¬ğŸ‡§ English](README.md) | [ğŸ‡ªğŸ‡¸ EspaÃ±ol](README_ES.md)

Framework para ejecutar **algoritmos metaheurÃ­sticos** (GA, PSO, ACO) con **aceleraciÃ³n GPU** y soporte experimental para ejecuciÃ³n distribuida en clÃºsteres mediante **MPI**.

Incluye ejemplos prÃ¡cticos de:
- ğŸ”¹ **SelecciÃ³n de caracterÃ­sticas** en problemas de clasificaciÃ³n
- ğŸ”¹ **Traveling Salesman Problem (TSP)**

---

## ğŸ“¦ Requisitos (OBLIGATORIOS)

âš ï¸ Actualmente la librerÃ­a **solo funciona con GPU NVIDIA**. No hay modo CPU puro.

- ğŸ–¥ï¸ **GPU NVIDIA** con Compute Capability â‰¥ 7.0 (recomendado 8.0+)  
- ğŸ”§ **Driver NVIDIA** actualizado (`nvidia-smi`)  
- ğŸ¯ **CUDA Toolkit 12.x** (`nvcc --version`)  
- ğŸ **Python 3.8+**  
- âš™ï¸ **GCC/G++ â‰¥ 9** (compatible con CUDA)  
- ğŸ› ï¸ **Make** (para compilar mÃ³dulos)  
- ğŸ“¦ Dependencias Python (`requirements.txt`)  
- ğŸŒ (Opcional, solo cluster) **OpenMPI**  

InstalaciÃ³n dependencias Python:
```bash
pip install -r requirements.txt
```

Verificar entorno:
```bash
nvidia-smi
nvcc --version
```

---

## âš™ï¸ CompilaciÃ³n

Compilar extensiones (obligatorio antes de usar):
```bash
./build.sh
```
GenerarÃ¡ librerÃ­as compartidas (`.so`) usadas internamente.  
Reconstruir si se actualiza CUDA o cambia GPU:
```bash
make clean && ./build.sh
```

---

## ğŸ—‚ï¸ Estructura del proyecto

```
â”œâ”€â”€ algorithms/    # Algoritmos (GA, PSO, ACO)
â”œâ”€â”€ problems/      # Definiciones de problemas (CLAS, TSP)
â”œâ”€â”€ cpp/           # CÃ³digo C++/CUDA
â”œâ”€â”€ results/       # Salidas (CSV, grÃ¡ficos, Excel)
â”œâ”€â”€ datasets/      # Conjuntos de datos
â”œâ”€â”€ docs/          # DocumentaciÃ³n Sphinx
â”œâ”€â”€ clas.py        # Ejemplo: ClasificaciÃ³n + selecciÃ³n de caracterÃ­sticas
â”œâ”€â”€ tsp.py         # Ejemplo: TSP con instancias TSPLIB
â”œâ”€â”€ cluster.py     # Ejemplo: EjecuciÃ³n distribuida (MPI)
â”œâ”€â”€ cluster_main.py# EjecuciÃ³n distribuida de alto nivel (MPI)
â”œâ”€â”€ build.sh       # Script de compilaciÃ³n
â”œâ”€â”€ Makefile       # Proceso de build GPU
â””â”€â”€ requirements.txt
```

---

## ğŸš€ InstalaciÃ³n rÃ¡pida

1. Clonar repositorio  
2. Instalar dependencias Python  
3. Compilar mÃ³dulos GPU  
```bash
./build.sh
```

4. Ejecutar ejemplos:

ClasificaciÃ³n:
```bash
python clas.py datasets/Clas/bank.csv -a ga -e gpu --iterations 100
```

TSP:
```bash
python tsp.py datasets/TSP/berlin52.tsp -a pso -e gpu --iterations 1000
```

---

## ğŸ§© Ejemplos de API

### ClasificaciÃ³n
```python
import pandas as pd
from problems.clas_problem import ClasProblem
from algorithms import GA
from clas import preprocess_bank_marketing_dataset

df = pd.read_csv("datasets/Clas/bank.csv")
df = preprocess_bank_marketing_dataset(df)
X = df.drop(columns=["y"]).values
y = df["y"].values

problem = ClasProblem(X, y, alpha=0.5, threshold=0.1)
ga = GA(problem, population_size=64, executer='gpu')
best_solution = ga.fit(iterations=100)
best_fitness = problem.fitness(best_solution)
print("Mejor fitness:", best_fitness)
```

### TSP
```python
from problems.tsp_problem import TSPProblem
from algorithms.aco import ACO
from tsp import read_tsp_file, extract_coords, build_distance_matrix
import numpy as np

meta, node_lines, edge_lines = read_tsp_file("datasets/TSP/berlin52.tsp")
coords_arr = extract_coords(node_lines) if node_lines else None
dist_matrix = build_distance_matrix(meta, coords_arr, edge_lines)

dist_matrix_np = np.array(dist_matrix, dtype=np.float32)

problem = TSPProblem(dist_matrix_np)
aco = ACO(problem, colony_size=100, executer='gpu')
best_path = aco.fit(iterations=1000)
best_distance = problem.fitness(best_path)
print("Mejor distancia:", best_distance)
```

---

## ğŸ–¥ï¸ Ejecutores disponibles

- âš¡ **gpu** â†’ GPU (recomendado)  
- ğŸ§© **cluster** â†’ Distribuido con MPI (experimental)  
- ğŸŒ **single** â†’ CPU secuencial (funcional pero lento)  
- ğŸ”€ **multi** â†’ CPU multihilo (funcional pero lento)  
- âš ï¸ **hybrid** â†’ CPU+GPU (no recomendado)

---

## ğŸ› ï¸ PersonalizaciÃ³n

### â• Nuevo algoritmo
1. Heredar de `Algorithm`  
2. Implementar:
   - `__init__` (pasar `problem`, `executer`)  
   - `fit` (lÃ³gica principal)  
   - `fit_mpi` (opcional)  
3. (Opcional) Integrar con problemas existentes con `patch_problem`

### â• Nuevo problema
1. Crear clase en `problems/`  
2. Implementar mÃ©todos (`fitness`, generaciÃ³n de soluciones, etc.)  
3. (Opcional) AÃ±adir soporte en ejecutores existentes

---

## ğŸ ResoluciÃ³n de problemas

- âŒ `CUDA driver not found` â†’ Actualizar driver / reiniciar  
- âŒ Error al importar `.so` â†’ `make clean && ./build.sh`  
- âŒ `mpirun: command not found` â†’ Instalar OpenMPI (`sudo apt install openmpi-bin`)  

---

## ğŸ“– DocumentaciÃ³n

```bash
cd docs
make html
```
Abrir: `docs/_build/html/index.html`

---

## ğŸ“Š Estado

- âœ… **GPU**: estable y recomendado  
- âš ï¸ **Cluster (MPI)**: funcional pero experimental  
- âš ï¸ **CPU single/multi**: funciona pero lento  
- âŒ **Hybrid**: no recomendado

---

## ğŸ“œ Licencia

MIT (ver `LICENSE`)

---

## ğŸ‘¤ Autor

**Isaac Brao Aissaoni**, 2025